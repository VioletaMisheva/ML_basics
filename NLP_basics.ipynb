{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes, even basic NLP approches, such as BOW or Tfidf lead to decent performance in many tasks. In this notebook, I use a subset of IMDB movie reviews and process the data before training a supervised model to detect the sentiment. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data\n",
    "\n",
    "data = pd.read_csv('IMDB_sample.csv', index_col=None)\n",
    "data = data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7501, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This short spoof can be found on Elite's Mille...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A singularly unfunny musical comedy that artif...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An excellent series, masterfully acted and dir...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The master of movie spectacle Cecil B. De Mill...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was gifted with this movie as it had such a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  This short spoof can be found on Elite's Mille...      0\n",
       "1  A singularly unfunny musical comedy that artif...      0\n",
       "2  An excellent series, masterfully acted and dir...      1\n",
       "3  The master of movie spectacle Cecil B. De Mill...      1\n",
       "4  I was gifted with this movie as it had such a ...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature for lenght of review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use the nltk module and its word_tokenize function to translate each review in tokens. Then I will loop over each tokenized review and count its length. I assign this to a new feature, which accounts for the length of a review.\n",
    "\n",
    "We construct thus a simple feature but it can be pretty informative in certain contexts and can increase the predictive performance of our models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's get a feel for how nltk works. Let's test it with a simple string. The output is a list of the string, split into tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'weather', 'is', 'great', 'today']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = \"the weather is great today\"\n",
    "word_tokenize(my_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first review in the data set:  This short spoof can be found on Elite's Millennium Edition DVD of \"Night of the Living Dead\". Good thing to as I would have never went even a tad out of my way to see it.Replacing zombies with bread sounds just like silly harmless fun on paper. In execution, it's a different matter. This short didn't even elicit a chuckle from me. I really never thought I'd say this, but \"Night of the Day of the Dawn of the Son of the Bride of the Return of the Revenge of the Terror of the Attack of the Evil, Mutant, Alien, Flesh Eating, Hellbound, Zombified Living Dead Part 2: In Shocking 2-D\" was a VERY better parody and not nearly as lame or boring.<br /><br />My Grade: F\n",
      "The first list of the tokens:  ['This', 'short', 'spoof', 'can', 'be', 'found', 'on', 'Elite', \"'s\", 'Millennium', 'Edition', 'DVD', 'of', '``', 'Night', 'of', 'the', 'Living', 'Dead', \"''\", '.', 'Good', 'thing', 'to', 'as', 'I', 'would', 'have', 'never', 'went', 'even', 'a', 'tad', 'out', 'of', 'my', 'way', 'to', 'see', 'it.Replacing', 'zombies', 'with', 'bread', 'sounds', 'just', 'like', 'silly', 'harmless', 'fun', 'on', 'paper', '.', 'In', 'execution', ',', 'it', \"'s\", 'a', 'different', 'matter', '.', 'This', 'short', 'did', \"n't\", 'even', 'elicit', 'a', 'chuckle', 'from', 'me', '.', 'I', 'really', 'never', 'thought', 'I', \"'d\", 'say', 'this', ',', 'but', '``', 'Night', 'of', 'the', 'Day', 'of', 'the', 'Dawn', 'of', 'the', 'Son', 'of', 'the', 'Bride', 'of', 'the', 'Return', 'of', 'the', 'Revenge', 'of', 'the', 'Terror', 'of', 'the', 'Attack', 'of', 'the', 'Evil', ',', 'Mutant', ',', 'Alien', ',', 'Flesh', 'Eating', ',', 'Hellbound', ',', 'Zombified', 'Living', 'Dead', 'Part', '2', ':', 'In', 'Shocking', '2-D', \"''\", 'was', 'a', 'VERY', 'better', 'parody', 'and', 'not', 'nearly', 'as', 'lame', 'or', 'boring.', '<', 'br', '/', '>', '<', 'br', '/', '>', 'My', 'Grade', ':', 'F']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "# List comprehension to tokenize the reviews: the result is a list\n",
    "tokens = [word_tokenize(review) for review in data.review]\n",
    "\n",
    "# Tokens will be a list of lists, where each inner list is a single review. Let's check whether that's indeed the case.\n",
    "print('The first review in the data set: ', data.iloc[0,0])\n",
    "print('The first list of the tokens: ', tokens[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 155\n"
     ]
    }
   ],
   "source": [
    "# We create an empty list for the length of tokens in each review, then loop over the tokens list, which remember is a list\n",
    "# of lists, count how many tokens we have in each inner list and append it to the length_tokens. \n",
    "length_tokens = []\n",
    "for item in range(len(tokens)):\n",
    "    length_tokens.append(len(tokens[item]))\n",
    "\n",
    "print(length_tokens[0], len(tokens[0]))\n",
    "data['n_words']= length_tokens\n",
    "#nw = pd.Series(length_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>n_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This short spoof can be found on Elite's Mille...</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A singularly unfunny musical comedy that artif...</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An excellent series, masterfully acted and dir...</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The master of movie spectacle Cecil B. De Mill...</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was gifted with this movie as it had such a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  n_words\n",
       "0  This short spoof can be found on Elite's Mille...      0      155\n",
       "1  A singularly unfunny musical comedy that artif...      0      646\n",
       "2  An excellent series, masterfully acted and dir...      1      121\n",
       "3  The master of movie spectacle Cecil B. De Mill...      1      128\n",
       "4  I was gifted with this movie as it had such a ...      0      248"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another thing we might want to do is to detect the language of each review because not all of them are necessarily in English. Or it could be that some sentences are in English, others in a different language within the same review.\n",
    "\n",
    "We will use the langdetect package (another alternative is langid package and they functions very similarly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nl:0.9999977669757246]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example of langdetect \n",
    "\n",
    "import langdetect\n",
    "foreign_string = 'ik vind her echt heel saai!'\n",
    "\n",
    "langdetect.detect_langs(foreign_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the output is in the form of ['language': likelihood]. We might want to capture only the 'nl' part. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[nl', '0.9999951271122164]']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the list to a string, then split on :\n",
    "str(langdetect.detect_langs(foreign_string)).split(':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[nl'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now extract the first element of this split\n",
    "str(langdetect.detect_langs(foreign_string)).split(':')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nl'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we want to get rid of the [, we need to do one more filtering step, chained to the previous\n",
    "str(langdetect.detect_langs(foreign_string)).split(':')[0][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the desired output. We will follow a similar approach to creating a feature for the length of each review. Here, after the langdetect package is applied to each step, we still need to perform the above cleaning step, to extract only the first, string part of the output of the detect_langs function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [] \n",
    "\n",
    "for i in range(len(data)):\n",
    "    languages.append(langdetect.detect_langs(data.iloc[i, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform the languages2 list \n",
    "languages = [str(lang).split(':')[0][1:] for lang in languages]\n",
    "data['language'] = languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>n_words</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This short spoof can be found on Elite's Mille...</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A singularly unfunny musical comedy that artif...</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An excellent series, masterfully acted and dir...</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The master of movie spectacle Cecil B. De Mill...</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was gifted with this movie as it had such a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  n_words language\n",
       "0  This short spoof can be found on Elite's Mille...      0      155       en\n",
       "1  A singularly unfunny musical comedy that artif...      0      646       en\n",
       "2  An excellent series, masterfully acted and dir...      1      121       en\n",
       "3  The master of movie spectacle Cecil B. De Mill...      1      128       en\n",
       "4  I was gifted with this movie as it had such a ...      0      248       en"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's inspect how the data looks like now\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count/tfidf vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sklearn has a function called CountVectorizer to transform the review column to BOW, and a TfidfVectorizer, which transform the review into a tfidf vocabulary.\n",
    "\n",
    "The functions are almost identical in the parameters they take. I will explore here the TfIDFvectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7501x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 342906 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the required library\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS\n",
    "\n",
    "# I expand the default ENGLISH_STOP_WORDS with words related to movies and reviews\n",
    "\n",
    "my_stop_words = ENGLISH_STOP_WORDS.union(['movie', 'film', 'cinema', 'theatre'])\n",
    "\n",
    "# Define the vectorizer, specifying the stop_words argument, the max_features (it will take the 1000 most frequent words)\n",
    "# and the token_pattern, which specifies I don't want any digits\n",
    "vect = TfidfVectorizer(max_features=1000, stop_words = my_stop_words, token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b').fit(data.review)\n",
    "tfidf = vect.transform(data.review)\n",
    "\n",
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actors</th>\n",
       "      <th>actress</th>\n",
       "      <th>...</th>\n",
       "      <th>wrong</th>\n",
       "      <th>wrote</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.049654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106637</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  accent  act    acted    acting    action  actor  \\\n",
       "0   0.0         0.0     0.0  0.0  0.00000  0.000000  0.000000    0.0   \n",
       "1   0.0         0.0     0.0  0.0  0.00000  0.049654  0.000000    0.0   \n",
       "2   0.0         0.0     0.0  0.0  0.22474  0.000000  0.000000    0.0   \n",
       "3   0.0         0.0     0.0  0.0  0.00000  0.000000  0.137626    0.0   \n",
       "4   0.0         0.0     0.0  0.0  0.00000  0.000000  0.094979    0.0   \n",
       "\n",
       "     actors  actress  ...     wrong  wrote  yeah      year  years  yes  york  \\\n",
       "0  0.000000      0.0  ...  0.000000    0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "1  0.057781      0.0  ...  0.000000    0.0   0.0  0.140262    0.0  0.0   0.0   \n",
       "2  0.000000      0.0  ...  0.000000    0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "3  0.000000      0.0  ...  0.000000    0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "4  0.000000      0.0  ...  0.106637    0.0   0.0  0.000000    0.0  0.0   0.0   \n",
       "\n",
       "      young  zombie   zombies  \n",
       "0  0.000000     0.0  0.218637  \n",
       "1  0.000000     0.0  0.000000  \n",
       "2  0.156487     0.0  0.000000  \n",
       "3  0.131886     0.0  0.000000  \n",
       "4  0.000000     0.0  0.000000  \n",
       "\n",
       "[5 rows x 1000 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The output is a sparse matrix, we can transform it to a pandas DF very easily!\n",
    "X_df = pd.DataFrame(tfidf.toarray() , columns = vect.get_feature_names())\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to concatenate the X_df with the rest of the data and the two features we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>n_words</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  n_words  language\n",
       "0      0      155         1\n",
       "1      0      646         1\n",
       "2      1      121         1\n",
       "3      1      128         1\n",
       "4      0      248         1"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_slice = data.iloc[:, 1:]\n",
    "# Recode the language to be binary, so that it is == 1 if the language is en, 0 otherwise\n",
    "data_slice['language'] = data_slice['language'].apply(lambda x: 1 if x=='en' else 0)\n",
    "data_slice.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>able</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>accent</th>\n",
       "      <th>act</th>\n",
       "      <th>acted</th>\n",
       "      <th>acting</th>\n",
       "      <th>action</th>\n",
       "      <th>actor</th>\n",
       "      <th>actors</th>\n",
       "      <th>actress</th>\n",
       "      <th>...</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yes</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>label</th>\n",
       "      <th>n_words</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218637</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.049654</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22474</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137626</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1003 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   able  absolutely  accent  act    acted    acting    action  actor  \\\n",
       "0   0.0         0.0     0.0  0.0  0.00000  0.000000  0.000000    0.0   \n",
       "1   0.0         0.0     0.0  0.0  0.00000  0.049654  0.000000    0.0   \n",
       "2   0.0         0.0     0.0  0.0  0.22474  0.000000  0.000000    0.0   \n",
       "3   0.0         0.0     0.0  0.0  0.00000  0.000000  0.137626    0.0   \n",
       "4   0.0         0.0     0.0  0.0  0.00000  0.000000  0.094979    0.0   \n",
       "\n",
       "     actors  actress  ...      year  years  yes  york     young  zombie  \\\n",
       "0  0.000000      0.0  ...  0.000000    0.0  0.0   0.0  0.000000     0.0   \n",
       "1  0.057781      0.0  ...  0.140262    0.0  0.0   0.0  0.000000     0.0   \n",
       "2  0.000000      0.0  ...  0.000000    0.0  0.0   0.0  0.156487     0.0   \n",
       "3  0.000000      0.0  ...  0.000000    0.0  0.0   0.0  0.131886     0.0   \n",
       "4  0.000000      0.0  ...  0.000000    0.0  0.0   0.0  0.000000     0.0   \n",
       "\n",
       "    zombies  label  n_words  language  \n",
       "0  0.218637      0      155         1  \n",
       "1  0.000000      0      646         1  \n",
       "2  0.000000      1      121         1  \n",
       "3  0.000000      1      128         1  \n",
       "4  0.000000      0      248         1  \n",
       "\n",
       "[5 rows x 1003 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the two data sets together\n",
    "\n",
    "data_for_modelling = pd.concat([X_df, data_slice], axis=1)\n",
    "data_for_modelling.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can continue with a regular supervised learning modelling, where the label is the target. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
